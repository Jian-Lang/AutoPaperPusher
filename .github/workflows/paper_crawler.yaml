name: Paper Crawler

on:
  schedule:
    - cron: '0 22 * * *'  # UTC 22:00 = 北京时间 06:00
  workflow_dispatch:

jobs:
  crawl-and-send:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run crawler and send email
      env:
        EMAIL_USERNAME: ${{ secrets.EMAIL_USERNAME }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        KEYWORDS: ${{ vars.KEYWORDS }}
      run: |
        python -c "
        from src.crawler import fetch_dblp_papers, fetch_arxiv_papers, format_email_content
        from src.mailer import send_email
        import os
        import json
        
        # 解析关键词列表
        keywords = json.loads(os.environ.get('KEYWORDS'))
        
        # 获取论文
        dblp_papers = fetch_dblp_papers(keywords)
        arxiv_papers = fetch_arxiv_papers(keywords)
        
        # 合并所有论文
        all_papers = dblp_papers + arxiv_papers
        
        # 格式化并发送邮件
        content = format_email_content(all_papers)
        send_email(content, os.environ.get('RECIPIENT_EMAIL'))
        "
